{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install -y gdown\nimport os\n\n\n# Define the path for the new folder\nfolder_path1 = '/kaggle/working/data/ed/train'\nfolder_path2 = '/kaggle/working/data/ed/test'\nfolder_path3 = '/kaggle/working/data/ed/valid'\n\n# Create the folder\nos.makedirs(folder_path1, exist_ok=True)\nos.makedirs(folder_path3, exist_ok=True)\nos.makedirs(folder_path3, exist_ok=True)\n!gdown 1-0pGAN5cq4LJuh4nWLwwhwujtmZdUzRC\n!gdown 1-06DRqJbVNZBw5uwjJ-7wgrNnS7UyuYe\n!gdown 1-5JlZ8RGOi01yj6I_qMF9chImOFitYFp\n\n\n!unzip ed_train.zip -d /kaggle/working/data/ed/train\n!unzip ed_test.zip -d /kaggle/working/data/ed/test\n!unzip ed_valid.zip -d /kaggle/working/data/ed/valid\n\n%cd /kaggle/working/data/ed\n!gdown 15Ek_F8WgH6Cqf-IUBRyPcVABAuto-6N3\n%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:20:55.646100Z","iopub.execute_input":"2024-09-03T09:20:55.646480Z","iopub.status.idle":"2024-09-03T09:22:44.164911Z","shell.execute_reply.started":"2024-09-03T09:20:55.646441Z","shell.execute_reply":"2024-09-03T09:22:44.163769Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nChannels:\n - rapidsai\n - nvidia\n - nodefaults\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n    certifi-2024.8.30          |     pyhd8ed1ab_0         160 KB  conda-forge\n    filelock-3.15.4            |     pyhd8ed1ab_0          17 KB  conda-forge\n    gdown-5.2.0                |     pyhd8ed1ab_0          21 KB  conda-forge\n    openssl-3.3.1              |       hb9d3cd8_3         2.8 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         3.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  filelock           conda-forge/noarch::filelock-3.15.4-pyhd8ed1ab_0 \n  gdown              conda-forge/noarch::gdown-5.2.0-pyhd8ed1ab_0 \n\nThe following packages will be UPDATED:\n\n  ca-certificates                       2024.7.4-hbcca054_0 --> 2024.8.30-hbcca054_0 \n  certifi                             2024.7.4-pyhd8ed1ab_0 --> 2024.8.30-pyhd8ed1ab_0 \n  openssl                                  3.3.1-h4bc722e_2 --> 3.3.1-hb9d3cd8_3 \n\n\n\nDownloading and Extracting Packages:\nopenssl-3.3.1        | 2.8 MB    |                                       |   0% \ncertifi-2024.8.30    | 160 KB    |                                       |   0% \u001b[A\n\nca-certificates-2024 | 155 KB    |                                       |   0% \u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\nopenssl-3.3.1        | 2.8 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\ncertifi-2024.8.30    | 160 KB    | ##############8                       |  40% \u001b[A\n\nca-certificates-2024 | 155 KB    | ###8                                  |  10% \u001b[A\u001b[A\n\n\n\nfilelock-3.15.4      | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nfilelock-3.15.4      | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\nopenssl-3.3.1        | 2.8 MB    | ##################################3   |  93% \u001b[A\n\n                                                                                \u001b[A\u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nDownloading...\nFrom: https://drive.google.com/uc?id=1-0pGAN5cq4LJuh4nWLwwhwujtmZdUzRC\nTo: /kaggle/working/ed_test.zip\n100%|███████████████████████████████████████| 4.85M/4.85M [00:00<00:00, 118MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1-06DRqJbVNZBw5uwjJ-7wgrNnS7UyuYe\nFrom (redirected): https://drive.google.com/uc?id=1-06DRqJbVNZBw5uwjJ-7wgrNnS7UyuYe&confirm=t&uuid=996851fc-99ab-4dbf-ae83-ec956248740a\nTo: /kaggle/working/ed_train.zip\n100%|██████████████████████████████████████| 34.5M/34.5M [00:00<00:00, 66.3MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1-5JlZ8RGOi01yj6I_qMF9chImOFitYFp\nTo: /kaggle/working/ed_valid.zip\n100%|██████████████████████████████████████| 5.02M/5.02M [00:00<00:00, 29.4MB/s]\nArchive:  ed_train.zip\n extracting: /kaggle/working/data/ed/train/speaker_ids.txt  \n extracting: /kaggle/working/data/ed/train/uttrs.txt  \n extracting: /kaggle/working/data/ed/train/dialogs.txt  \n extracting: /kaggle/working/data/ed/train/context_emots.txt  \n extracting: /kaggle/working/data/ed/train/uttr_emots.npy  \nArchive:  ed_test.zip\n extracting: /kaggle/working/data/ed/test/prompts.txt  \n extracting: /kaggle/working/data/ed/test/dialogs.txt  \n extracting: /kaggle/working/data/ed/test/speaker_ids.txt  \n extracting: /kaggle/working/data/ed/test/uttrs.txt  \n extracting: /kaggle/working/data/ed/test/uttr_emots.npy  \n extracting: /kaggle/working/data/ed/test/context_emots.txt  \n extracting: /kaggle/working/data/ed/test/dialogs_partial.txt  \nArchive:  ed_valid.zip\n extracting: /kaggle/working/data/ed/valid/context_emots.txt  \n extracting: /kaggle/working/data/ed/valid/speaker_ids.txt  \n extracting: /kaggle/working/data/ed/valid/dialogs.txt  \n extracting: /kaggle/working/data/ed/valid/uttrs.txt  \n extracting: /kaggle/working/data/ed/valid/uttr_emots.npy  \n/kaggle/working/data/ed\nDownloading...\nFrom: https://drive.google.com/uc?id=15Ek_F8WgH6Cqf-IUBRyPcVABAuto-6N3\nTo: /kaggle/working/data/ed/test_2000_index.npy\n100%|██████████████████████████████████████| 16.1k/16.1k [00:00<00:00, 42.5MB/s]\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch==2.3.0 torchvision torchaudio -f https://download.pytorch.org/whl/cu121/torch_stable.html","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:24:24.997533Z","iopub.execute_input":"2024-09-03T09:24:24.997939Z","iopub.status.idle":"2024-09-03T09:27:50.813031Z","shell.execute_reply.started":"2024-09-03T09:24:24.997899Z","shell.execute_reply":"2024-09-03T09:27:50.811929Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\nCollecting torch==2.3.0\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.0 (from torch==2.3.0)\n  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0)\n  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0) (1.3.0)\nDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 triton-2.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check Python version\nimport sys\nprint(\"Python version:\", sys.version)\n\n# Check PyTorch version\nimport torch\nprint(\"PyTorch version:\", torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:28:37.011380Z","iopub.execute_input":"2024-09-03T09:28:37.011806Z","iopub.status.idle":"2024-09-03T09:28:38.689624Z","shell.execute_reply.started":"2024-09-03T09:28:37.011764Z","shell.execute_reply":"2024-09-03T09:28:38.688692Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\nPyTorch version: 2.3.0+cu121\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install \"unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git\"","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:29:10.264766Z","iopub.execute_input":"2024-09-03T09:29:10.265276Z","iopub.status.idle":"2024-09-03T09:30:38.073040Z","shell.execute_reply.started":"2024-09-03T09:29:10.265239Z","shell.execute_reply":"2024-09-03T09:30:38.071976Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-p3_3fdop/unsloth_8825910d13b742f7a5fa890d2c28a575\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-p3_3fdop/unsloth_8825910d13b742f7a5fa890d2c28a575\n  Resolved https://github.com/unslothai/unsloth.git to commit c085a4562c704b94e76c17df1363a8fc6cd07e85\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0+cu121)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\nCollecting xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (164.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (21.3)\nCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tyro-0.8.10-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: transformers>=4.43.2 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.44.0)\nRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.21.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\nRequirement already satisfied: accelerate>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.33.0)\nCollecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading trl-0.10.1-py3-none-any.whl.metadata (12 kB)\nCollecting peft!=0.11.0,>=0.7.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.24.6)\nCollecting hf-transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.6.68)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting torch (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting triton==2.3.1 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.10.1-py3-none-any.whl (280 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.10-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.8-py3-none-any.whl size=151411 sha256=71d56b084a8fe163f7ed898b7eeee154cfba54adc249662c40300b11ff670bee\n  Stored in directory: /tmp/pip-ephem-wheel-cache-204bgg4a/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth, triton, shtab, hf-transfer, tyro, torch, xformers, bitsandbytes, trl, peft\n  Attempting uninstall: triton\n    Found existing installation: triton 2.3.0\n    Uninstalling triton-2.3.0:\n      Successfully uninstalled triton-2.3.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.3.0+cu121\n    Uninstalling torch-2.3.0+cu121:\n      Successfully uninstalled torch-2.3.0+cu121\nSuccessfully installed bitsandbytes-0.43.3 hf-transfer-0.1.8 peft-0.12.0 shtab-1.7.1 torch-2.3.1 triton-2.3.1 trl-0.10.1 tyro-0.8.10 unsloth-2024.8 xformers-0.0.27\n","output_type":"stream"}]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:31:02.721987Z","iopub.execute_input":"2024-09-03T09:31:02.722988Z","iopub.status.idle":"2024-09-03T09:31:20.811792Z","shell.execute_reply.started":"2024-09-03T09:31:02.722936Z","shell.execute_reply":"2024-09-03T09:31:20.809562Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"}]},{"cell_type":"code","source":"class ExtendedModel(FastLanguageModel):\n    def __init__(self, config):\n        super().__init__(config)\n        # Add custom embeddings\n        \n        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n        self.segment_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n        self.emotion_embeddings = nn.Embedding(config.emotion_vocab_size, config.hidden_size)\n\n    def forward(self, input_ids, position_ids, segment_ids, emotion_ids):\n        # Embed the inputs\n        word_embeds = self.word_embedding(input_ids)\n        position_embeds = self.position_embedding(position_ids)\n        segment_embeds = self.segment_embedding(segment_ids)\n        emotion_embeds = self.emotion_embedding(emotion_ids)\n        \n        # Sum all embeddings\n        embeddings = word_embeds + position_embeds + segment_embeds + emotion_embeds\n       \n        # Pass through the rest of the model\n        outputs = super().forward(inputs_embeds=embeddings, **kwargs)\n        return output\n# # Extend Model with Additional Embeddings\n# class ExtendedModel(FastLanguageModel):\n#     def __init__(self, config):\n#         super(ExtendedModel, self).__init__()\n#         self.base_model = base_model\n        \n#         self.model = base_model\n#         del self.model\n#         del self.base_model\n#         torch.cuda.empty_cache()\n#         # Inherit config from base_model\n#         self.config = base_model.config\n#         self._saved_temp_tokenizer = getattr(base_model, '_saved_temp_tokenizer', None)  # Copy the tokenizer attribute if it exists\n#         self.max_seq_length = max_seq_length\n        \n#         # Additional Embedding Layers\n#         self.word_embedding = nn.Embedding(vocab_size, model.config.hidden_size)\n#         self.position_embedding = nn.Embedding(max_seq_length, model.config.hidden_size)\n#         self.segment_embedding = nn.Embedding(segment_vocab_size, model.config.hidden_size)\n#         self.emotion_embedding = nn.Embedding(emotion_vocab_size, model.config.hidden_size)\n    \n#     def forward(self, input_ids, position_ids, segment_ids, emotion_ids):\n#         # Embed the inputs\n#         word_embeds = self.word_embedding(input_ids)\n#         position_embeds = self.position_embedding(position_ids)\n#         segment_embeds = self.segment_embedding(segment_ids)\n#         emotion_embeds = self.emotion_embedding(emotion_ids)\n        \n#         # Sum all embeddings\n#         embeddings = word_embeds + position_embeds + segment_embeds + emotion_embeds\n        \n#         # Pass embeddings through the base model\n#         output = self.base_model(inputs_embeds=embeddings)\n        \n#         return output\n#     def get_input_embeddings(self):\n#         return self.word_embedding\n\n#     def set_input_embeddings(self, value):\n#         self.word_embedding = value\n    \n#     def get_output_embeddings(self):\n#         return self.base_model.get_output_embeddings()\n    \n#     def prepare_inputs_for_generation(self, input_ids, **kwargs):\n#         # Use the base model's method to prepare inputs\n#         return self.base_model.prepare_inputs_for_generation(input_ids, **kwargs)\n\n#     def generate(self, **kwargs):\n#         # Use the base model's generate method\n#         return self.base_model.generate(**kwargs)\n    \n#     def gradient_checkpointing_enable(self):\n#         # Enable gradient checkpointing in the base model\n#         return self.base_model.gradient_checkpointing_enable()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:32:08.349656Z","iopub.execute_input":"2024-09-03T09:32:08.350974Z","iopub.status.idle":"2024-09-03T09:32:08.362348Z","shell.execute_reply.started":"2024-09-03T09:32:08.350925Z","shell.execute_reply":"2024-09-03T09:32:08.361420Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\ndtype = torch.float32\nload_in_4bit = True","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:32:37.968546Z","iopub.execute_input":"2024-09-03T09:32:37.968920Z","iopub.status.idle":"2024-09-03T09:32:37.973313Z","shell.execute_reply.started":"2024-09-03T09:32:37.968886Z","shell.execute_reply":"2024-09-03T09:32:37.972290Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Load the pre-trained model and tokenizer\nmodel1,tokenizer = ExtendedModel.from_pretrained(\n    model_name,\n    max_seq_length = 512,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n    token=\"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\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:32:52.588809Z","iopub.execute_input":"2024-09-03T09:32:52.589565Z","iopub.status.idle":"2024-09-03T09:33:15.868528Z","shell.execute_reply.started":"2024-09-03T09:32:52.589516Z","shell.execute_reply":"2024-09-03T09:33:15.867488Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.27. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae27d32116b749a3b5203c9b3d0b9849"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6964525053e84ff081d9c2a7b6e6192b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"339081907eee46489f745e2e1536e539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b8c4744bf964bf0b6f8907ff4bdf279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7711270685cb41829a7b1aac77537178"}},"metadata":{}}]},{"cell_type":"code","source":"# Configure the PEFT model\nmodel2 = FastLanguageModel.get_peft_model(\n    model1,\n    r=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_alpha=16,\n    lora_dropout=0,\n    bias=\"none\",\n    use_gradient_checkpointing=\"unsloth\",\n    random_state=3407,\n    use_rslora=False,\n    loftq_config=None\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:34:18.612986Z","iopub.execute_input":"2024-09-03T09:34:18.613402Z","iopub.status.idle":"2024-09-03T09:34:23.534047Z","shell.execute_reply.started":"2024-09-03T09:34:18.613365Z","shell.execute_reply":"2024-09-03T09:34:23.533168Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom os.path import join","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:34:45.943363Z","iopub.execute_input":"2024-09-03T09:34:45.943749Z","iopub.status.idle":"2024-09-03T09:34:45.948734Z","shell.execute_reply.started":"2024-09-03T09:34:45.943714Z","shell.execute_reply":"2024-09-03T09:34:45.947723Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def create_ed_datasets(tokenizer, path, buffer_size, batch_size, max_length, index = None):\n    print('Vocabulary size is {}.'.format(tokenizer.vocab_size))\n\n    def create_dataset(read_path, cascade = True):\n        print('Reading data from \\\"{}\\\"...'.format(read_path))\n\n        if not cascade:\n            with open(join(read_path, 'prompts.txt'), 'r', encoding = 'utf-8') as f:\n                all_prompts = f.read().splitlines()\n            with open(join(read_path, 'context_emots.txt'), 'r', encoding = 'utf-8') as f:\n                all_context_emots = f.read().splitlines()\n        else:\n            all_prompts = []\n            all_context_emots = []\n\n        with open(join(read_path, 'uttrs.txt'), 'r', encoding = 'utf-8') as f:\n            uttrs = f.read().splitlines()\n\n        # For test set, we randomly choose a turn to be target.\n        dialogs_file = 'dialogs_partial.txt' if not cascade else 'dialogs.txt'\n        with open(join(read_path, dialogs_file), 'r', encoding = 'utf-8') as f:\n            dialogs = [(int(i) for i in line.split(',')) for line in f.read().splitlines()]\n\n        uttr_emots = np.load(join(read_path, 'uttr_emots.npy'))\n        assert len(uttrs) == uttr_emots.shape[0]\n        uttr_emots = np.argsort(uttr_emots, axis = 1)\n\n        SOS_ID = tokenizer.encode('<s>')[0]\n        EOS_ID = tokenizer.encode('</s>')[0]\n\n        # RoBERTa uses 1 as the padding value\n        # For RoBERTa style input: <s> u1 </s> </s> u2 </s> </s> u3 </s> ...\n        inputs = np.ones((len(uttrs), max_length), dtype = np.int32)\n\n        # These three are always associated with RoBERTa style input\n        input_segments = np.zeros((len(uttrs), max_length), dtype = np.int32)\n        input_emots = np.zeros((len(uttrs), max_length), dtype = np.int32)\n        target_segments = np.zeros((len(uttrs), max_length), dtype = np.int32)\n        target_emots = np.zeros(len(uttrs), dtype = np.int32)\n\n        # These two are always the same for any input style: <s> target </s>\n        targets_i = np.ones((len(uttrs), max_length), dtype = np.int32)\n        targets_r = np.ones((len(uttrs), max_length), dtype = np.int32)\n\n        n = 0\n        indices = []\n        for ind, (s, t) in tqdm(enumerate(dialogs), total = len(dialogs)):\n            if t - s < 2:\n                continue\n\n            if cascade:\n                uttr_ids = tokenizer.encode(uttrs[s])\n\n                inp_ids = [SOS_ID] + uttr_ids + [EOS_ID]\n                inp_seg_ids = [0] * (len(uttr_ids) + 2)\n                inp_emots = [uttr_emots[s,-1]] * (len(uttr_ids) + 2)\n                for i in range(s + 1, t):\n                    u = ' '.join(uttrs[s:i])\n                    if len(u.split()) > max_length: break\n\n                    uttr_ids = tokenizer.encode(uttrs[i])\n                    tar_ids = [SOS_ID] + uttr_ids + [EOS_ID]\n                    tar_seg_ids = [(i - s) % 2] * (len(uttr_ids) + 2)\n                    if (len(inp_ids) <= max_length and len(tar_ids) - 1 <= max_length):\n                        inputs[n,:len(inp_ids)] = inp_ids\n                        input_segments[n,:len(inp_seg_ids)] = inp_seg_ids\n                        input_emots[n,:len(inp_ids)] = inp_emots\n                        target_emots[n] = uttr_emots[i,-1]\n                        targets_i[n,:len(tar_ids)-1] = tar_ids[:-1]\n                        targets_r[n,:len(tar_ids)-1] = tar_ids[1:]\n                        target_segments[n,:len(tar_seg_ids)] = tar_seg_ids\n                        n += 1\n\n                    inp_ids += ([EOS_ID] + uttr_ids + [EOS_ID])\n                    inp_seg_ids += [(i - s) % 2] * (len(uttr_ids) + 2)\n                    inp_emots += [uttr_emots[i,-1]] * (len(uttr_ids) + 2)\n            else:\n                u = ' '.join(uttrs[s:t-1])\n                if len(u.split()) > max_length: continue\n\n                uttr_ids = tokenizer.encode(uttrs[s])\n                inp_ids = [SOS_ID] + uttr_ids + [EOS_ID]\n                inp_seg_ids = [0] * (len(uttr_ids) + 2)\n                inp_emots = [uttr_emots[s,-1]] * (len(uttr_ids) + 2)\n                for i in range(s + 1, t - 1):\n                    uttr_ids = tokenizer.encode(uttrs[i])\n                    inp_ids += ([EOS_ID] + uttr_ids + [EOS_ID])\n                    inp_seg_ids += [(i - s) % 2] * (len(uttr_ids) + 2)\n                    inp_emots += [uttr_emots[i,-1]] * (len(uttr_ids) + 2)\n                uttr_ids = tokenizer.encode(uttrs[t - 1])\n                tar_ids = [SOS_ID] + uttr_ids + [EOS_ID]\n                tar_seg_ids = [(t - s - 1) % 2] * (len(uttr_ids) + 2)\n\n                if (len(inp_ids) <= max_length and len(tar_ids) - 1 <= max_length):\n                    inputs[n,:len(inp_ids)] = inp_ids\n                    input_segments[n,:len(inp_seg_ids)] = inp_seg_ids\n                    input_emots[n,:len(inp_ids)] = inp_emots\n                    target_emots[n] = uttr_emots[t-1,-1]\n                    targets_i[n,:len(tar_ids)-1] = tar_ids[:-1]\n                    targets_r[n,:len(tar_ids)-1] = tar_ids[1:]\n                    target_segments[n,:len(tar_seg_ids)] = tar_seg_ids\n                    indices.append(ind)\n                    n += 1\n\n        print('Created dataset with {} examples.'.format(n))\n        print('Number of indices: {}'.format(len(indices)))\n\n        prompts = []\n        for ind in indices:\n            prompts.append((all_context_emots[ind], all_prompts[ind]))\n\n        inputs = inputs[:n,:]\n        input_segments = input_segments[:n,:]\n        input_emots = input_emots[:n,:]\n        targets_i = targets_i[:n,:]\n        targets_r = targets_r[:n,:]\n        target_segments = target_segments[:n,:]\n        target_emots = target_emots[:n]\n\n        if not cascade and index is not None:\n            inputs = inputs[index]\n            input_segments = input_segments[index]\n            input_emots = input_emots[index]\n            targets_i = targets_i[index]\n            targets_r = targets_r[index]\n            target_segments = target_segments[index]\n            target_emots = target_emots[index]\n\n        return (tf.data.Dataset.from_tensor_slices(inputs),\n                tf.data.Dataset.from_tensor_slices(input_segments),\n                tf.data.Dataset.from_tensor_slices(input_emots),\n                tf.data.Dataset.from_tensor_slices(targets_i),\n                tf.data.Dataset.from_tensor_slices(targets_r),\n                tf.data.Dataset.from_tensor_slices(target_segments),\n                tf.data.Dataset.from_tensor_slices(target_emots)), prompts, inputs.shape[0]\n\n    train_dataset, _, _ = create_dataset(join(path, 'train'))\n    val_dataset, _, _ = create_dataset(join(path, 'valid'))\n    test_dataset, prompts, N = create_dataset(join(path, 'test'), cascade = False)\n\n    train_dataset = tf.data.Dataset.zip(train_dataset).shuffle(buffer_size).batch(batch_size)\n    val_dataset = tf.data.Dataset.zip(val_dataset).batch(batch_size)\n    test_dataset = tf.data.Dataset.zip(test_dataset).batch(batch_size)\n\n    return train_dataset, val_dataset, test_dataset, prompts, N","metadata":{"execution":{"iopub.status.busy":"2024-09-03T09:34:51.341206Z","iopub.execute_input":"2024-09-03T09:34:51.342007Z","iopub.status.idle":"2024-09-03T09:34:51.377449Z","shell.execute_reply.started":"2024-09-03T09:34:51.341937Z","shell.execute_reply":"2024-09-03T09:34:51.376347Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"max_length = 105  # Maximum number of tokens\nbuffer_size = 100000\nbatch_size = 512\ndata_path='/kaggle/working/data/ed'\ntrain_dataset, val_dataset, test_dataset, _, _ = create_ed_datasets(tokenizer,data_path, buffer_size, batch_size, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:21:01.085249Z","iopub.execute_input":"2024-09-03T10:21:01.085651Z","iopub.status.idle":"2024-09-03T10:21:13.155398Z","shell.execute_reply.started":"2024-09-03T10:21:01.085611Z","shell.execute_reply":"2024-09-03T10:21:13.153164Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Vocabulary size is 128000.\nReading data from \"/kaggle/working/data/ed/train\"...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 19533/19533 [00:09<00:00, 2080.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Created dataset with 62611 examples.\nNumber of indices: 0\nReading data from \"/kaggle/working/data/ed/valid\"...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2770/2770 [00:01<00:00, 2016.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Created dataset with 8954 examples.\nNumber of indices: 0\nReading data from \"/kaggle/working/data/ed/test\"...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2547/2547 [00:00<00:00, 3334.60it/s]","output_type":"stream"},{"name":"stdout","text":"Created dataset with 2489 examples.\nNumber of indices: 2489\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"for (batch, inputs) in enumerate(train_dataset):\n                \n    inp, inp_seg, inp_emot, tar_inp, tar_real, tar_seg, tar_emot = inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:21:36.100983Z","iopub.execute_input":"2024-09-03T10:21:36.101971Z","iopub.status.idle":"2024-09-03T10:21:37.189936Z","shell.execute_reply.started":"2024-09-03T10:21:36.101916Z","shell.execute_reply":"2024-09-03T10:21:37.188799Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:21:42.443023Z","iopub.execute_input":"2024-09-03T10:21:42.443406Z","iopub.status.idle":"2024-09-03T10:21:42.449751Z","shell.execute_reply.started":"2024-09-03T10:21:42.443370Z","shell.execute_reply":"2024-09-03T10:21:42.448752Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"\nclass ConversationDataset(Dataset):\n    def __init__(self, input_ids, input_segment_ids, input_emotion_ids, target_ids, target_segment_ids, target_emotion_ids):\n        self.input_ids = input_ids.numpy()\n        self.input_segment_ids = input_segment_ids.numpy()\n        self.input_emotion_ids = input_emotion_ids.numpy()\n        self.target_ids = target_ids.numpy()\n        self.target_segment_ids = target_segment_ids.numpy()\n        self.target_emotion_ids = target_emotion_ids.numpy()\n        self.column_names = ['input_ids', 'input_segment_ids', 'input_emotion_ids', 'labels', 'target_segment_ids', 'target_emotion_ids']\n        \n    def __len__(self):\n        return len(self.input_ids)\n    \n    def __getitem__(self, idx):\n        return {\n            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n            'input_segment_ids': torch.tensor(self.input_segment_ids[idx], dtype=torch.long),\n            'input_emotion_ids': torch.tensor(self.input_emotion_ids[idx], dtype=torch.long),\n            'labels': torch.tensor(self.target_ids[idx], dtype=torch.long),\n            'target_segment_ids': torch.tensor(self.target_segment_ids[idx], dtype=torch.long),\n            'target_emotion_ids': torch.tensor(self.target_emotion_ids[idx], dtype=torch.long)\n        }\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:21:56.895358Z","iopub.execute_input":"2024-09-03T10:21:56.896283Z","iopub.status.idle":"2024-09-03T10:21:56.906967Z","shell.execute_reply.started":"2024-09-03T10:21:56.896241Z","shell.execute_reply":"2024-09-03T10:21:56.905806Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Create datasets\ntrain_dataset1 = ConversationDataset(inp, inp_seg, inp_emot, tar_real, tar_seg, tar_emot )\n\n# Create data loaders\nbatch_size = 1 # Adjust based on your GPU memory\ntrain_loader = DataLoader(train_dataset1, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:35:33.231510Z","iopub.execute_input":"2024-09-03T10:35:33.232264Z","iopub.status.idle":"2024-09-03T10:35:33.239084Z","shell.execute_reply.started":"2024-09-03T10:35:33.232219Z","shell.execute_reply":"2024-09-03T10:35:33.237847Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:28:24.667794Z","iopub.execute_input":"2024-09-03T10:28:24.668645Z","iopub.status.idle":"2024-09-03T10:28:24.674282Z","shell.execute_reply.started":"2024-09-03T10:28:24.668608Z","shell.execute_reply":"2024-09-03T10:28:24.673193Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model2,\n    tokenizer = tokenizer,\n    train_dataset = train_dataset1,\n    dataset_text_field = \"text\",\n    max_seq_length = 512,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 1,\n        gradient_accumulation_steps = 50,\n        warmup_steps = 5,\n        max_steps = 30,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        \n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:37:09.079242Z","iopub.execute_input":"2024-09-03T10:37:09.080240Z","iopub.status.idle":"2024-09-03T10:37:09.158983Z","shell.execute_reply.started":"2024-09-03T10:37:09.080195Z","shell.execute_reply":"2024-09-03T10:37:09.157922Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:37:11.657651Z","iopub.execute_input":"2024-09-03T10:37:11.658577Z","iopub.status.idle":"2024-09-03T10:37:15.668587Z","shell.execute_reply.started":"2024-09-03T10:37:11.658535Z","shell.execute_reply":"2024-09-03T10:37:15.666724Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 147 | Num Epochs = 15\nO^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 50\n\\        /    Total batch size = 50 | Total steps = 30\n \"-____-\"     Number of trainable parameters = 41,943,040\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<string>:145\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n","File \u001b[0;32m<string>:363\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3328\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3328\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3334\u001b[0m ):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3373\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3372\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3373\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3374\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3375\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","    \u001b[0;31m[... skipping similar frames: ConvertOutputsToFp32.__call__ at line 807 (7 times), autocast_decorator.<locals>.decorate_autocast at line 16 (7 times), convert_outputs_to_fp32.<locals>.forward at line 819 (7 times)]\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unsloth/models/llama.py:1030\u001b[0m, in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_dynamo\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPeftModelForCausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1029\u001b[0m ):\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:188\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unsloth/models/llama.py:957\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m    955\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 957\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    959\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtorch_dtype)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU "],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1002.00 MiB. GPU ","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}