{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install -y gdown\nimport os\n\n\n# Define the path for the new folder\nfolder_path1 = '/kaggle/working/data/ed/train'\nfolder_path2 = '/kaggle/working/data/ed/test'\nfolder_path3 = '/kaggle/working/data/ed/valid'\n\n# Create the folder\nos.makedirs(folder_path1, exist_ok=True)\nos.makedirs(folder_path3, exist_ok=True)\nos.makedirs(folder_path3, exist_ok=True)\n!gdown 1-0pGAN5cq4LJuh4nWLwwhwujtmZdUzRC\n!gdown 1-06DRqJbVNZBw5uwjJ-7wgrNnS7UyuYe\n!gdown 1-5JlZ8RGOi01yj6I_qMF9chImOFitYFp\n\n\n!unzip ed_train.zip -d /kaggle/working/data/ed/train\n!unzip ed_test.zip -d /kaggle/working/data/ed/test\n!unzip ed_valid.zip -d /kaggle/working/data/ed/valid\n\n%cd /kaggle/working/data/ed\n!gdown 15Ek_F8WgH6Cqf-IUBRyPcVABAuto-6N3\n%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:34:09.058251Z","iopub.execute_input":"2024-09-03T11:34:09.058973Z","iopub.status.idle":"2024-09-03T11:36:12.651522Z","shell.execute_reply.started":"2024-09-03T11:34:09.058930Z","shell.execute_reply":"2024-09-03T11:36:12.650443Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='conda.anaconda.org', port=443): Read timed out. (read timeout=5)\")': /rapidsai/notices.json\n\ndone\nChannels:\n - rapidsai\n - nvidia\n - nodefaults\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n    certifi-2024.8.30          |     pyhd8ed1ab_0         160 KB  conda-forge\n    filelock-3.15.4            |     pyhd8ed1ab_0          17 KB  conda-forge\n    gdown-5.2.0                |     pyhd8ed1ab_0          21 KB  conda-forge\n    openssl-3.3.1              |       hb9d3cd8_3         2.8 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         3.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n  filelock           conda-forge/noarch::filelock-3.15.4-pyhd8ed1ab_0 \n  gdown              conda-forge/noarch::gdown-5.2.0-pyhd8ed1ab_0 \n\nThe following packages will be UPDATED:\n\n  ca-certificates                       2024.7.4-hbcca054_0 --> 2024.8.30-hbcca054_0 \n  certifi                             2024.7.4-pyhd8ed1ab_0 --> 2024.8.30-pyhd8ed1ab_0 \n  openssl                                  3.3.1-h4bc722e_2 --> 3.3.1-hb9d3cd8_3 \n\n\n\nDownloading and Extracting Packages:\nopenssl-3.3.1        | 2.8 MB    |                                       |   0% \ncertifi-2024.8.30    | 160 KB    |                                       |   0% \u001b[A\n\nca-certificates-2024 | 155 KB    |                                       |   0% \u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\nopenssl-3.3.1        | 2.8 MB    | 8                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\n\nca-certificates-2024 | 155 KB    | ###8                                  |  10% \u001b[A\u001b[A\ncertifi-2024.8.30    | 160 KB    | ###7                                  |  10% \u001b[A\n\n\n\nfilelock-3.15.4      | 17 KB     | ##################################4   |  93% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\n\nfilelock-3.15.4      | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\nca-certificates-2024 | 155 KB    | ##################################### | 100% \u001b[A\u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nDownloading...\nFrom: https://drive.google.com/uc?id=1-0pGAN5cq4LJuh4nWLwwhwujtmZdUzRC\nTo: /kaggle/working/ed_test.zip\n100%|██████████████████████████████████████| 4.85M/4.85M [00:00<00:00, 84.5MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1-06DRqJbVNZBw5uwjJ-7wgrNnS7UyuYe\nFrom (redirected): https://drive.google.com/uc?id=1-06DRqJbVNZBw5uwjJ-7wgrNnS7UyuYe&confirm=t&uuid=c6dbff6b-d3a1-4bd0-b050-417b4996a014\nTo: /kaggle/working/ed_train.zip\n100%|███████████████████████████████████████| 34.5M/34.5M [00:00<00:00, 137MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1-5JlZ8RGOi01yj6I_qMF9chImOFitYFp\nTo: /kaggle/working/ed_valid.zip\n100%|███████████████████████████████████████| 5.02M/5.02M [00:00<00:00, 227MB/s]\nArchive:  ed_train.zip\n extracting: /kaggle/working/data/ed/train/speaker_ids.txt  \n extracting: /kaggle/working/data/ed/train/uttrs.txt  \n extracting: /kaggle/working/data/ed/train/dialogs.txt  \n extracting: /kaggle/working/data/ed/train/context_emots.txt  \n extracting: /kaggle/working/data/ed/train/uttr_emots.npy  \nArchive:  ed_test.zip\n extracting: /kaggle/working/data/ed/test/prompts.txt  \n extracting: /kaggle/working/data/ed/test/dialogs.txt  \n extracting: /kaggle/working/data/ed/test/speaker_ids.txt  \n extracting: /kaggle/working/data/ed/test/uttrs.txt  \n extracting: /kaggle/working/data/ed/test/uttr_emots.npy  \n extracting: /kaggle/working/data/ed/test/context_emots.txt  \n extracting: /kaggle/working/data/ed/test/dialogs_partial.txt  \nArchive:  ed_valid.zip\n extracting: /kaggle/working/data/ed/valid/context_emots.txt  \n extracting: /kaggle/working/data/ed/valid/speaker_ids.txt  \n extracting: /kaggle/working/data/ed/valid/dialogs.txt  \n extracting: /kaggle/working/data/ed/valid/uttrs.txt  \n extracting: /kaggle/working/data/ed/valid/uttr_emots.npy  \n/kaggle/working/data/ed\nDownloading...\nFrom: https://drive.google.com/uc?id=15Ek_F8WgH6Cqf-IUBRyPcVABAuto-6N3\nTo: /kaggle/working/data/ed/test_2000_index.npy\n100%|██████████████████████████████████████| 16.1k/16.1k [00:00<00:00, 34.1MB/s]\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch==2.3.0 torchvision torchaudio -f https://download.pytorch.org/whl/cu121/torch_stable.html","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:36:12.653474Z","iopub.execute_input":"2024-09-03T11:36:12.653796Z","iopub.status.idle":"2024-09-03T11:39:00.295789Z","shell.execute_reply.started":"2024-09-03T11:36:12.653763Z","shell.execute_reply":"2024-09-03T11:39:00.294635Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\nCollecting torch==2.3.0\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.0 (from torch==2.3.0)\n  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0)\n  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0) (1.3.0)\nDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 triton-2.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check Python version\nimport sys\nprint(\"Python version:\", sys.version)\n\n# Check PyTorch version\nimport torch\nprint(\"PyTorch version:\", torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:39:00.297149Z","iopub.execute_input":"2024-09-03T11:39:00.297461Z","iopub.status.idle":"2024-09-03T11:39:02.035660Z","shell.execute_reply.started":"2024-09-03T11:39:00.297426Z","shell.execute_reply":"2024-09-03T11:39:02.034701Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\nPyTorch version: 2.3.0+cu121\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install \"unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git\"","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:39:02.037393Z","iopub.execute_input":"2024-09-03T11:39:02.037786Z","iopub.status.idle":"2024-09-03T11:42:49.730175Z","shell.execute_reply.started":"2024-09-03T11:39:02.037751Z","shell.execute_reply":"2024-09-03T11:42:49.729027Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-kk8w_90z/unsloth_f0ec46cbb070466d921bbbc492c4ffea\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-kk8w_90z/unsloth_f0ec46cbb070466d921bbbc492c4ffea\n  Resolved https://github.com/unslothai/unsloth.git to commit c085a4562c704b94e76c17df1363a8fc6cd07e85\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0+cu121)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\nCollecting xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (164.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (21.3)\nCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tyro-0.8.10-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: transformers>=4.43.2 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.44.0)\nRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.21.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\nRequirement already satisfied: accelerate>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.33.0)\nCollecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading trl-0.10.1-py3-none-any.whl.metadata (12 kB)\nCollecting peft!=0.11.0,>=0.7.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.24.6)\nCollecting hf-transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (12.6.68)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting torch (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting triton==2.3.1 (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch230]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.10.1-py3-none-any.whl (280 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.10-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.8-py3-none-any.whl size=151411 sha256=2a4b5677e1105487f74513b900b488bc108c5e6feb6b8eb59c7304aed3d2ad33\n  Stored in directory: /tmp/pip-ephem-wheel-cache-73m3xjb6/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth, triton, shtab, hf-transfer, tyro, torch, xformers, bitsandbytes, trl, peft\n  Attempting uninstall: triton\n    Found existing installation: triton 2.3.0\n    Uninstalling triton-2.3.0:\n      Successfully uninstalled triton-2.3.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.3.0+cu121\n    Uninstalling torch-2.3.0+cu121:\n      Successfully uninstalled torch-2.3.0+cu121\nSuccessfully installed bitsandbytes-0.43.3 hf-transfer-0.1.8 peft-0.12.0 shtab-1.7.1 torch-2.3.1 triton-2.3.1 trl-0.10.1 tyro-0.8.10 unsloth-2024.8 xformers-0.0.27\n","output_type":"stream"}]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:42:49.731521Z","iopub.execute_input":"2024-09-03T11:42:49.731851Z","iopub.status.idle":"2024-09-03T11:43:11.221500Z","shell.execute_reply.started":"2024-09-03T11:42:49.731818Z","shell.execute_reply":"2024-09-03T11:43:11.220390Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2024-09-03T12:13:07.501985Z","iopub.execute_input":"2024-09-03T12:13:07.502758Z","iopub.status.idle":"2024-09-03T12:13:07.506999Z","shell.execute_reply.started":"2024-09-03T12:13:07.502717Z","shell.execute_reply":"2024-09-03T12:13:07.505929Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class ExtendedModel(FastLanguageModel):\n    def __init__(self, config):\n        super().__init__(config)\n        # Add custom embeddings\n        \n        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n        self.segment_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n        self.emotion_embeddings = nn.Embedding(config.emotion_vocab_size, config.hidden_size)\n\n    def forward(self, input_ids, position_ids, segment_ids, emotion_ids):\n        # Embed the inputs\n        word_embeds = self.word_embedding(input_ids)\n        position_embeds = self.position_embedding(position_ids)\n        segment_embeds = self.segment_embedding(segment_ids)\n        emotion_embeds = self.emotion_embedding(emotion_ids)\n        \n        # Sum all embeddings\n        embeddings = word_embeds + position_embeds + segment_embeds + emotion_embeds\n       \n        # Pass through the rest of the model\n        outputs = super().forward(inputs_embeds=embeddings, **kwargs)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T12:13:10.787494Z","iopub.execute_input":"2024-09-03T12:13:10.788267Z","iopub.status.idle":"2024-09-03T12:13:10.796260Z","shell.execute_reply.started":"2024-09-03T12:13:10.788226Z","shell.execute_reply":"2024-09-03T12:13:10.795198Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\ndtype = torch.float32\nload_in_4bit = True","metadata":{"execution":{"iopub.status.busy":"2024-09-03T12:10:02.233160Z","iopub.execute_input":"2024-09-03T12:10:02.234105Z","iopub.status.idle":"2024-09-03T12:10:02.239509Z","shell.execute_reply.started":"2024-09-03T12:10:02.234062Z","shell.execute_reply":"2024-09-03T12:10:02.238501Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the pre-trained model and tokenizer\nmodel1,tokenizer = ExtendedModel.from_pretrained(\n    model_name,\n    max_seq_length = 512,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n    token=\"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\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T12:13:21.849129Z","iopub.execute_input":"2024-09-03T12:13:21.849573Z","iopub.status.idle":"2024-09-03T12:13:24.652182Z","shell.execute_reply.started":"2024-09-03T12:13:21.849535Z","shell.execute_reply":"2024-09-03T12:13:24.650674Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.27. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py:1405: UserWarning: Current model requires 34603008.0 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the pre-trained model and tokenizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model1,tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mExtendedModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhf_nbqpjghiXFLSEcZbghKVMFccokZCoHkNMM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unsloth/models/loader.py:301\u001b[0m, in \u001b[0;36mFastLanguageModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m     tokenizer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(resize_model_vocab)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unsloth/models/llama.py:1565\u001b[0m, in \u001b[0;36mFastLlamaModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;66;03m# Cannot be None, since HF now checks for the config\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit: kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m bnb_config\n\u001b[0;32m-> 1565\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# quantization_config     = bnb_config,\u001b[39;49;00m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;66;03m# Return old flag\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_HUB_ENABLE_HF_TRANSFER\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m old_hf_transfer\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3890\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3887\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m infer_auto_device_map(model, dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdevice_map_kwargs)\n\u001b[1;32m   3889\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3890\u001b[0m         \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3893\u001b[0m     model\u001b[38;5;241m.\u001b[39mtie_weights()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:86\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     83\u001b[0m         key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules_to_not_convert\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m---> 86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`from_pretrained`. Check \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.39.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have a version of `bitsandbytes` that is not compatible with 4bit inference and training\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you have the latest version of `bitsandbytes` installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "],"ename":"ValueError","evalue":"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ","output_type":"error"}]},{"cell_type":"code","source":"# Ensure the model recognizes these target layers\nfor name, module in model1.named_modules():\n    if isinstance(module, nn.Embedding):\n        print(f\"{name}: {module}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-03T12:13:37.141910Z","iopub.execute_input":"2024-09-03T12:13:37.142661Z","iopub.status.idle":"2024-09-03T12:13:37.149188Z","shell.execute_reply.started":"2024-09-03T12:13:37.142619Z","shell.execute_reply":"2024-09-03T12:13:37.148192Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"model.embed_tokens: Embedding(128256, 4096)\n","output_type":"stream"}]},{"cell_type":"code","source":"target_modules = [\"embeddings.word_embeddings\", \"embeddings.position_embeddings\", \"emotion_embeddings\"]\n\n# Ensure the model recognizes these target layers\nfor name, module in model1.named_modules():\n    if name in target_modules:\n        print(f\"Modifying layer: {name}\")\n        # Apply modifications or fine-tuning steps here","metadata":{"execution":{"iopub.status.busy":"2024-09-03T12:12:44.043164Z","iopub.execute_input":"2024-09-03T12:12:44.044069Z","iopub.status.idle":"2024-09-03T12:12:44.070168Z","shell.execute_reply.started":"2024-09-03T12:12:44.044028Z","shell.execute_reply":"2024-09-03T12:12:44.069105Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)\nLlamaModel(\n  (embed_tokens): Embedding(128256, 4096)\n  (layers): ModuleList(\n    (0-31): 32 x LlamaDecoderLayer(\n      (self_attn): LlamaAttention(\n        (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n        (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n        (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n        (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (mlp): LlamaMLP(\n        (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n        (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n        (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n        (act_fn): SiLU()\n      )\n      (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n    )\n  )\n  (norm): LlamaRMSNorm((4096,), eps=1e-05)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nEmbedding(128256, 4096)\nModuleList(\n  (0-31): 32 x LlamaDecoderLayer(\n    (self_attn): LlamaAttention(\n      (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n      (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n      (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n      (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n      (rotary_emb): LlamaRotaryEmbedding()\n    )\n    (mlp): LlamaMLP(\n      (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n      (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n      (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n      (act_fn): SiLU()\n    )\n    (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n    (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  )\n)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaDecoderLayer(\n  (self_attn): LlamaAttention(\n    (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (mlp): LlamaMLP(\n    (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n    (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n    (act_fn): SiLU()\n  )\n  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n)\nLlamaAttention(\n  (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n  (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n  (rotary_emb): LlamaRotaryEmbedding()\n)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=1024, bias=False)\nLinear4bit(in_features=4096, out_features=4096, bias=False)\nLlamaRotaryEmbedding()\nLlamaMLP(\n  (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n  (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n  (act_fn): SiLU()\n)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=4096, out_features=14336, bias=False)\nLinear4bit(in_features=14336, out_features=4096, bias=False)\nSiLU()\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRMSNorm((4096,), eps=1e-05)\nLlamaRotaryEmbedding()\nLinear(in_features=4096, out_features=128256, bias=False)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Configure the PEFT model\nmodel1 = FastLanguageModel.get_peft_model(\n    model1,\n    r=16,\n    target_modules=[\"embeddings.word_embeddings\", \"embeddings.position_embeddings\", \"embeddings.emotion_embeddings\",\"embeddings.segment_embeddings\"]\n    lora_alpha=16,\n    lora_dropout=0,\n    bias=\"none\",\n    use_gradient_checkpointing=\"unsloth\",\n    random_state=3407,\n    use_rslora=False,\n    loftq_config=None\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom os.path import join","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_ed_datasets(tokenizer, path, buffer_size, batch_size, max_length, index = None):\n    print('Vocabulary size is {}.'.format(tokenizer.vocab_size))\n\n    def create_dataset(read_path, cascade = True):\n        print('Reading data from \\\"{}\\\"...'.format(read_path))\n\n        if not cascade:\n            with open(join(read_path, 'prompts.txt'), 'r', encoding = 'utf-8') as f:\n                all_prompts = f.read().splitlines()\n            with open(join(read_path, 'context_emots.txt'), 'r', encoding = 'utf-8') as f:\n                all_context_emots = f.read().splitlines()\n        else:\n            all_prompts = []\n            all_context_emots = []\n\n        with open(join(read_path, 'uttrs.txt'), 'r', encoding = 'utf-8') as f:\n            uttrs = f.read().splitlines()\n\n        # For test set, we randomly choose a turn to be target.\n        dialogs_file = 'dialogs_partial.txt' if not cascade else 'dialogs.txt'\n        with open(join(read_path, dialogs_file), 'r', encoding = 'utf-8') as f:\n            dialogs = [(int(i) for i in line.split(',')) for line in f.read().splitlines()]\n\n        uttr_emots = np.load(join(read_path, 'uttr_emots.npy'))\n        assert len(uttrs) == uttr_emots.shape[0]\n        uttr_emots = np.argsort(uttr_emots, axis = 1)\n\n        SOS_ID = tokenizer.encode('<s>')[0]\n        EOS_ID = tokenizer.encode('</s>')[0]\n\n        # RoBERTa uses 1 as the padding value\n        # For RoBERTa style input: <s> u1 </s> </s> u2 </s> </s> u3 </s> ...\n        inputs = np.ones((len(uttrs), max_length), dtype = np.int32)\n\n        # These three are always associated with RoBERTa style input\n        input_segments = np.zeros((len(uttrs), max_length), dtype = np.int32)\n        input_emots = np.zeros((len(uttrs), max_length), dtype = np.int32)\n        target_segments = np.zeros((len(uttrs), max_length), dtype = np.int32)\n        target_emots = np.zeros(len(uttrs), dtype = np.int32)\n\n        # These two are always the same for any input style: <s> target </s>\n        targets_i = np.ones((len(uttrs), max_length), dtype = np.int32)\n        targets_r = np.ones((len(uttrs), max_length), dtype = np.int32)\n\n        n = 0\n        indices = []\n        for ind, (s, t) in tqdm(enumerate(dialogs), total = len(dialogs)):\n            if t - s < 2:\n                continue\n\n            if cascade:\n                uttr_ids = tokenizer.encode(uttrs[s])\n\n                inp_ids = [SOS_ID] + uttr_ids + [EOS_ID]\n                inp_seg_ids = [0] * (len(uttr_ids) + 2)\n                inp_emots = [uttr_emots[s,-1]] * (len(uttr_ids) + 2)\n                for i in range(s + 1, t):\n                    u = ' '.join(uttrs[s:i])\n                    if len(u.split()) > max_length: break\n\n                    uttr_ids = tokenizer.encode(uttrs[i])\n                    tar_ids = [SOS_ID] + uttr_ids + [EOS_ID]\n                    tar_seg_ids = [(i - s) % 2] * (len(uttr_ids) + 2)\n                    if (len(inp_ids) <= max_length and len(tar_ids) - 1 <= max_length):\n                        inputs[n,:len(inp_ids)] = inp_ids\n                        input_segments[n,:len(inp_seg_ids)] = inp_seg_ids\n                        input_emots[n,:len(inp_ids)] = inp_emots\n                        target_emots[n] = uttr_emots[i,-1]\n                        targets_i[n,:len(tar_ids)-1] = tar_ids[:-1]\n                        targets_r[n,:len(tar_ids)-1] = tar_ids[1:]\n                        target_segments[n,:len(tar_seg_ids)] = tar_seg_ids\n                        n += 1\n\n                    inp_ids += ([EOS_ID] + uttr_ids + [EOS_ID])\n                    inp_seg_ids += [(i - s) % 2] * (len(uttr_ids) + 2)\n                    inp_emots += [uttr_emots[i,-1]] * (len(uttr_ids) + 2)\n            else:\n                u = ' '.join(uttrs[s:t-1])\n                if len(u.split()) > max_length: continue\n\n                uttr_ids = tokenizer.encode(uttrs[s])\n                inp_ids = [SOS_ID] + uttr_ids + [EOS_ID]\n                inp_seg_ids = [0] * (len(uttr_ids) + 2)\n                inp_emots = [uttr_emots[s,-1]] * (len(uttr_ids) + 2)\n                for i in range(s + 1, t - 1):\n                    uttr_ids = tokenizer.encode(uttrs[i])\n                    inp_ids += ([EOS_ID] + uttr_ids + [EOS_ID])\n                    inp_seg_ids += [(i - s) % 2] * (len(uttr_ids) + 2)\n                    inp_emots += [uttr_emots[i,-1]] * (len(uttr_ids) + 2)\n                uttr_ids = tokenizer.encode(uttrs[t - 1])\n                tar_ids = [SOS_ID] + uttr_ids + [EOS_ID]\n                tar_seg_ids = [(t - s - 1) % 2] * (len(uttr_ids) + 2)\n\n                if (len(inp_ids) <= max_length and len(tar_ids) - 1 <= max_length):\n                    inputs[n,:len(inp_ids)] = inp_ids\n                    input_segments[n,:len(inp_seg_ids)] = inp_seg_ids\n                    input_emots[n,:len(inp_ids)] = inp_emots\n                    target_emots[n] = uttr_emots[t-1,-1]\n                    targets_i[n,:len(tar_ids)-1] = tar_ids[:-1]\n                    targets_r[n,:len(tar_ids)-1] = tar_ids[1:]\n                    target_segments[n,:len(tar_seg_ids)] = tar_seg_ids\n                    indices.append(ind)\n                    n += 1\n\n        print('Created dataset with {} examples.'.format(n))\n        print('Number of indices: {}'.format(len(indices)))\n\n        prompts = []\n        for ind in indices:\n            prompts.append((all_context_emots[ind], all_prompts[ind]))\n\n        inputs = inputs[:n,:]\n        input_segments = input_segments[:n,:]\n        input_emots = input_emots[:n,:]\n        targets_i = targets_i[:n,:]\n        targets_r = targets_r[:n,:]\n        target_segments = target_segments[:n,:]\n        target_emots = target_emots[:n]\n\n        if not cascade and index is not None:\n            inputs = inputs[index]\n            input_segments = input_segments[index]\n            input_emots = input_emots[index]\n            targets_i = targets_i[index]\n            targets_r = targets_r[index]\n            target_segments = target_segments[index]\n            target_emots = target_emots[index]\n\n        return (tf.data.Dataset.from_tensor_slices(inputs),\n                tf.data.Dataset.from_tensor_slices(input_segments),\n                tf.data.Dataset.from_tensor_slices(input_emots),\n                tf.data.Dataset.from_tensor_slices(targets_i),\n                tf.data.Dataset.from_tensor_slices(targets_r),\n                tf.data.Dataset.from_tensor_slices(target_segments),\n                tf.data.Dataset.from_tensor_slices(target_emots)), prompts, inputs.shape[0]\n\n    train_dataset, _, _ = create_dataset(join(path, 'train'))\n    val_dataset, _, _ = create_dataset(join(path, 'valid'))\n    test_dataset, prompts, N = create_dataset(join(path, 'test'), cascade = False)\n\n    train_dataset = tf.data.Dataset.zip(train_dataset).shuffle(buffer_size).batch(batch_size)\n    val_dataset = tf.data.Dataset.zip(val_dataset).batch(batch_size)\n    test_dataset = tf.data.Dataset.zip(test_dataset).batch(batch_size)\n\n    return train_dataset, val_dataset, test_dataset, prompts, N","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 105  # Maximum number of tokens\nbuffer_size = 100000\nbatch_size = 512\ndata_path='/kaggle/working/data/ed'\ntrain_dataset, val_dataset, test_dataset, _, _ = create_ed_datasets(tokenizer,data_path, buffer_size, batch_size, max_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (batch, inputs) in enumerate(train_dataset):\n                \n    inp, inp_seg, inp_emot, tar_inp, tar_real, tar_seg, tar_emot = inputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ConversationDataset(Dataset):\n    def __init__(self, input_ids, input_segment_ids, input_emotion_ids, target_ids, target_segment_ids, target_emotion_ids):\n        self.input_ids = input_ids.numpy()\n        self.input_segment_ids = input_segment_ids.numpy()\n        self.input_emotion_ids = input_emotion_ids.numpy()\n        self.target_ids = target_ids.numpy()\n        self.target_segment_ids = target_segment_ids.numpy()\n        self.target_emotion_ids = target_emotion_ids.numpy()\n        self.column_names = ['input_ids', 'input_segment_ids', 'input_emotion_ids', 'labels', 'target_segment_ids', 'target_emotion_ids']\n        \n    def __len__(self):\n        return len(self.input_ids)\n    \n    def __getitem__(self, idx):\n        return {\n            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n            'input_segment_ids': torch.tensor(self.input_segment_ids[idx], dtype=torch.long),\n            'input_emotion_ids': torch.tensor(self.input_emotion_ids[idx], dtype=torch.long),\n            'labels': torch.tensor(self.target_ids[idx], dtype=torch.long),\n            'target_segment_ids': torch.tensor(self.target_segment_ids[idx], dtype=torch.long),\n            'target_emotion_ids': torch.tensor(self.target_emotion_ids[idx], dtype=torch.long)\n        }\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create datasets\ntrain_dataset1 = ConversationDataset(inp, inp_seg, inp_emot, tar_real, tar_seg, tar_emot )\n\n# Create data loaders\nbatch_size = 1 # Adjust based on your GPU memory\ntrain_loader = DataLoader(train_dataset1, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model2,\n    tokenizer = tokenizer,\n    train_dataset = train_dataset1,\n    dataset_text_field = \"text\",\n    max_seq_length = 512,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 1,\n        gradient_accumulation_steps = 50,\n        warmup_steps = 5,\n        max_steps = 30,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        \n    ),\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}